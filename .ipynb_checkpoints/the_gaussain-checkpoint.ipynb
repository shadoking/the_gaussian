{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "417c1468",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\the_gaussian_splatting\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from argparse import ArgumentParser\n",
    "from typing import NamedTuple\n",
    "from plyfile import PlyData\n",
    "from pykdtree.kdtree import KDTree\n",
    "from utils.colmap_utils import (\n",
    "    read_extrinsics_binary, \n",
    "    read_intrinsics_binary, \n",
    "    read_points3D_binary, \n",
    "    read_points3D_text,\n",
    "    qvec2rotmat\n",
    ")\n",
    "from utils.camera_utils import focal2fov\n",
    "from utils.model_utils import InverseSigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d0e721",
   "metadata": {},
   "source": [
    "# 参数读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a80e8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取json配置文件\n",
    "with open('config.json','r') as file:\n",
    "    json_data = json.load(file)\n",
    "\n",
    "parser = ArgumentParser()\n",
    "for key, value in json_data.items():\n",
    "    parser.add_argument(f'--{key}', default=value)\n",
    "parser.add_argument(\"--detect_anomaly\", action=\"store_true\", default=False)\n",
    "parser.add_argument(\"--test_iterations\", nargs=\"+\", type=int, default=[100,1_000, 7_000, 30_000])\n",
    "parser.add_argument(\"--save_iterations\", nargs=\"+\", type=int, default=[100,1_000, 7_000, 30_000])   \n",
    "parser.add_argument(\"--checkpoint_iterations\", nargs=\"+\", type=int, default=[100, 1_000, 7_000, 30_000])\n",
    "parser.add_argument(\"--start_checkpoint\", type=str, default = None)\n",
    "args = parser.parse_args(args=['--source_path', './data',  '--model_path', './data/output'])\n",
    "#config = vars(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb18b89a",
   "metadata": {},
   "source": [
    "# 数据读取\n",
    "\n",
    "相机矩阵(4 X 4)：\n",
    "$\n",
    "viewMatrix = \\begin{bmatrix}\n",
    "R & T \\\\\n",
    "0 & 1\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "投影矩阵(4 X 4)：\n",
    "$\n",
    "projMatrix = \\begin{bmatrix}\n",
    "\\frac{2n}{r-l} & 0 & 0 & 0 \\\\\n",
    "0 & \\frac{2n}{t-b} & 0 & 0 \\\\\n",
    "0 & 0 & \\frac{f +n}{f - n} & \\frac{2nf}{n - f} \\\\\n",
    "0 & 0 & 1 & 0\n",
    "\\end{bmatrix}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5193e036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# camera_utils\n",
    "class BasicPointCloud(NamedTuple):\n",
    "    positions : np.array\n",
    "    colors : np.array\n",
    "    normals : np.array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2794240e",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# camera_utils\n",
    "class ImageInfo:\n",
    "    def __init__(self, image_name, image_path, image, image_width, image_height, R, T, fov_x, fov_y, device):\n",
    "        self.image = torch.from_numpy(image) # 需要时读入显存\n",
    "        self.image_name = image_name\n",
    "        self.image_path = image_path        \n",
    "        self.image_width = image_width\n",
    "        self.image_height = image_height\n",
    "        self.R = R\n",
    "        self.T = T\n",
    "        self.fov_x = fov_x\n",
    "        self.fov_y = fov_y\n",
    "        self.zfar = 100.0\n",
    "        self.znear = 0.01\n",
    "        \n",
    "        self.viewMatrix = self.getViewMatrix(self.R, self.T).to(device)\n",
    "        self.projMatrix = self.getProjMatrix(self.znear, self.zfar, self.fov_x, self.fov_y).to(device)\n",
    "        self.viewProjMatrix = self.viewMatrix @ self.projMatrix\n",
    "        self.cameraCenter = torch.inverse(self.viewMatrix)[:3, 3]\n",
    "        \n",
    "    def getViewMatrix(self, R, T):\n",
    "        viewMatrix = torch.eye(4, dtype=torch.float32)\n",
    "        viewMatrix[:3, :3] = torch.tensor(R, dtype=torch.float32)\n",
    "        viewMatrix[:3, 3] = torch.tensor(T, dtype=torch.float32)\n",
    "        \n",
    "        return viewMatrix\n",
    "        \n",
    "    def getProjMatrix(self, znear, zfar, fov_x, fov_y):\n",
    "        tan_fov_y = np.tan((fov_y / 2))\n",
    "        tan_fov_x = np.tan((fov_x / 2))\n",
    "        \n",
    "        top = tan_fov_y * znear\n",
    "        bottom = -top\n",
    "        right = tan_fov_x * znear\n",
    "        left = -right\n",
    "        \n",
    "        projMatrix = torch.zeros(4, 4)\n",
    "        projMatrix[0, 0] = 2.0 * znear / (right - left)\n",
    "        projMatrix[1, 1] = 2.0 * znear / (top - bottom)\n",
    "        projMatrix[2, 2] = zfar / (zfar - znear)\n",
    "        projMatrix[2, 3] = 2.0 * znear * zfar / (znear - zfar)\n",
    "        projMatrix[3, 3] = 1.0\n",
    "        \n",
    "        return projMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86f49b4f",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class GSDataLoader:\n",
    "    def __init__(self, data_path, reading_dir, device):\n",
    "        self.data_path = data_path\n",
    "        self.device = device\n",
    "        self.cameras = []\n",
    "        self.points = {}\n",
    "        self.loadColmap(reading_dir)\n",
    "    \n",
    "    def loadColmap(self, reading_dir):\n",
    "        # 读取相机\n",
    "        cameras_extrinsic_path = os.path.join(self.data_path, \"sparse/0/images.bin\")\n",
    "        cam_extrinsics = read_extrinsics_binary(cameras_extrinsic_path)        \n",
    "        cameras_intrinsic_path = os.path.join(self.data_path, \"sparse/0/cameras.bin\")\n",
    "        cam_intrinsics = read_intrinsics_binary(cameras_intrinsic_path)\n",
    "        \n",
    "        # 读取图片\n",
    "        images_folder=os.path.join(self.data_path, reading_dir)\n",
    "        self.cameras = []\n",
    "        for _, image_info in cam_extrinsics.items():\n",
    "            intr = cam_intrinsics[image_info.camera_id]\n",
    "\n",
    "            image_height = intr.height\n",
    "            image_width = intr.width\n",
    "\n",
    "            image_path = os.path.join(images_folder, image_info.name)\n",
    "            image = cv2.imread(image_path)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            R = qvec2rotmat(image_info.qvec)\n",
    "            T = image_info.tvec\n",
    "\n",
    "            if intr.model == \"SIMPLE_PINHOLE\":\n",
    "                # colmap params [f, cx, cy]\n",
    "                fov_y = focal2fov(intr.params[0], image_height)\n",
    "                fov_x = focal2fov(intr.params[0], image_width) \n",
    "            elif intr.model == \"PINHOLE\":\n",
    "                # colmap params [fx, fy, cx, cy]\n",
    "                fov_y = focal2fov(intr.params[1], image_height)\n",
    "                fov_x = focal2fov(intr.params[0], image_width)\n",
    "            else:\n",
    "                assert False, \"Colmap camera model not handled: only undistorted datasets (PINHOLE or SIMPLE_PINHOLE cameras) supported!\"\n",
    "\n",
    "            self.cameras.append(ImageInfo(\n",
    "                image_name=image_info.name, \n",
    "                image_path=image_path, \n",
    "                image=image, \n",
    "                image_width=image_width, \n",
    "                image_height=image_height, \n",
    "                R=R, T=T, \n",
    "                fov_x=fov_x,\n",
    "                fov_y=fov_y, \n",
    "                device=self.device))\n",
    "                \n",
    "        # 读取点云\n",
    "        ply_path = os.path.join(self.data_path, \"sparse/0/points3D.ply\")\n",
    "        plydata = PlyData.read(ply_path)\n",
    "        vertices = plydata['vertex']\n",
    "        positions = np.vstack([vertices['x'], vertices['y'], vertices['z']]).T\n",
    "        colors = np.vstack([vertices['red'], vertices['green'], vertices['blue']]).T / 255.0\n",
    "        normals = np.vstack([vertices['nx'], vertices['ny'], vertices['nz']]).T\n",
    "        self.points = BasicPointCloud(positions=positions, colors=colors, normals=normals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0b80a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "data = GSDataLoader(args.source_path, args.images, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae72ca47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b7b8008",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# GS模型\n",
    "\n",
    "四元数$q=(w, x, y, z)$，需满足$ w^2 + x^2 + y^2 + z^2 =1$ \n",
    "\n",
    "四元数转旋转矩阵：\n",
    "$\n",
    "R = \\begin{bmatrix}\n",
    "1 - 2y^2 - 2z^2 & 2xy - 2wz & 2xz + 2wy \\\\\n",
    "2xy + 2wz & 1 - 2x^2 - 2z^2 & 2yz - 2wx \\\\\n",
    "2xz - 2wy & 2yz + 2wx & 1 - 2x^2 - 2y^2\n",
    "\\end{bmatrix}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8624ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_utils\n",
    "def BuildRotation(r):\n",
    "    # 归一化\n",
    "    norm = torch.norm(r, dim=-1)\n",
    "    q = r / norm[:, None]\n",
    "    \n",
    "    R = torch.zeros((q.shaep[0], 3, 3), dtype=torch.float32, device='cuda')\n",
    "    \n",
    "    w = q[:, 0]\n",
    "    x = q[:, 1]\n",
    "    y = q[:, 2]\n",
    "    z = q[:, 3]\n",
    "    \n",
    "    R[:, 0, 0] = 1 - 2*y*y - 2*z*z\n",
    "    R[:, 0, 1] = 2*x*y-2*w*z\n",
    "    R[:, 0, 2] = 2*x*z + 2*w*y    \n",
    "    R[:, 1, 0] = 2*x*y + 2*w*z\n",
    "    R[:, 1, 1] = 1 - 2*x*x - 2*z*z\n",
    "    R[:, 1, 2] = 2*y*z - 2*w*x\n",
    "    R[:, 2, 0] = 2*x*z - 2*w*y\n",
    "    R[:, 2, 1] = 2*y*z + 2*w*x\n",
    "    R[:, 2, 2] = 1 - 2*x*x - 2*y*y\n",
    "    \n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66d1671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_utils\n",
    "def BuildRotationScaling(r, s):\n",
    "    U = torch.zeors((s.shape[0], 3, 3), dtype=torch.float32, device='cuda')\n",
    "    R = BuildRotation(r)\n",
    "    \n",
    "    U[:, 0, 0] = s[:, 0]\n",
    "    U[:, 1, 1] = s[:, 1]   \n",
    "    U[:, 2, 2] = s[:, 2]\n",
    "    \n",
    "    U = R @ U\n",
    "    \n",
    "    return U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823c489c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_utils\n",
    "def GetUTM(M):\n",
    "    utm = torch.zeros((M.shape[0], 6), dtype=torch.float32, device='cuda')\n",
    "    \n",
    "    utm[:, 0] = M[:, 0, 0]\n",
    "    utm[:, 1] = M[:, 0, 1]\n",
    "    utm[:, 2] = M[:, 0, 2]\n",
    "    utm[:, 3] = M[:, 1, 1]\n",
    "    utm[:, 4] = M[:, 1, 2]    \n",
    "    utm[:, 5] = M[:, 2, 2] \n",
    "    \n",
    "    return utm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b97a5cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sh_utils\n",
    "C0 = 0.28209479177387814\n",
    "def RGB2SH(rgb):\n",
    "    return (rgb - 0.5) / C0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a76852b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_34044\\1432531269.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mGSModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msh_degree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_sh_degree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msh_degree\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_xyz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class GSModel(nn.Module):\n",
    "    def __init__(self, sh_degree):\n",
    "        super().__init__()\n",
    "        self.max_sh_degree = sh_degree\n",
    "        self._xyz = torch.empty(0)\n",
    "        self._features_dc = torch.empty(0)\n",
    "        self._features_rest = torch.empty(0)\n",
    "        self._scaling = torch.empty(0)\n",
    "        self._rotation = torch.empty(0)\n",
    "        self._opacity = torch.empty(0)\n",
    "        self.setupFunctions()\n",
    "    \n",
    "    def setupFunctions(self):\n",
    "        def buildCvarianceFomRotationScaling(rotation, sacling, scaling_modifier):\n",
    "            U = BuildRotationScaling(rotation, scaling * scaling_modifier)\n",
    "            covariance = U @ U.transpose(1, 2)\n",
    "            utm = GetUTM(covariance)\n",
    "            return utm\n",
    "        \n",
    "        self.scaling_activation = torch.exp\n",
    "        self.scaling_inverse_activation = torch.log\n",
    "        \n",
    "        self.opacity_activation = torch.sigmoid\n",
    "        self.inverse_opacity_activation = InverseSigmoid\n",
    "        \n",
    "        self.rotation_activation = torch.nn.functional.normalize\n",
    "        \n",
    "        self.covariance_activation = buildCvarianceFomRotationScaling\n",
    "    \n",
    "    # 重点计算sacling的初始化尺度\n",
    "    def createFromPointCloud(self, point_cloud):\n",
    "        N = point_cloud.positions.shape[0]\n",
    "        # 位置\n",
    "        xyz = torch.tensor(point_cloud.positions, dtype=torch.float32, device='cuda')\n",
    "        # 不透明度\n",
    "        opacity = torch.ones((N, 1), dtype=torch.float32, device='cuda') * InverseSigmoid(0.1)\n",
    "        # 旋转\n",
    "        rotation = torch.zeros((N, 4), dtype=torch.float32, device='cuda')\n",
    "        rotation[:, 0] = 1.0\n",
    "        # 尺度\n",
    "        kd_tree = KDTree(point_cloud.positions)\n",
    "        dist, idx = kd_tree.query(point_cloud.positions, k=4)\n",
    "        mean_dist = dist[:, 1:].mean(axis=1)\n",
    "        mean_dist = torch.tensor(np.log(mean_dist), dtype=torch.float32, device='cuda').unsqueeze(dim=1)\n",
    "        scaling = torch.ones(3) * mean_dist\n",
    "        #颜色\n",
    "        fused_color = torch.tensor(RGB2SH(data.points.colors), dtype=torch.float32, device='cuda')\n",
    "        features = torch.zeros((N, 3, (self.max_sh_degree+1) ** 2), dtype=torch.float32, device='cuda')\n",
    "        features[:, :, 0] = fused_color\n",
    "        \n",
    "        \n",
    "        self._xyz = nn.Parameter(xyz.requires_grad_(True))\n",
    "        self._features_dc = nn.Parameter(features[:,:,0].requires_grad_(True))\n",
    "        self._features_rest = nn.Parameter(features[:,:,1:].requires_grad_(True))\n",
    "        self._scaling = nn.Parameter(scaling.requires_grad_(True))\n",
    "        self._rotation = nn.Parameter(rotation.requires_grad_(True))\n",
    "        self._opacity = nn.Parameter(opacity.requires_grad_(True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a102c8d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.77153874, -0.77153874, -0.98006272],\n",
       "       [-0.78544033, -0.85494833, -0.99396432],\n",
       "       [ 1.73074905,  1.75855225,  1.74465065],\n",
       "       ...,\n",
       "       [-1.35540589, -1.28589789, -1.38320908],\n",
       "       [-1.1468819 , -1.03566911, -1.1885867 ],\n",
       "       [-0.0208524 ,  0.0208524 ,  0.14596679]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RGB2SH(data.points.colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b3ef78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9a7359",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c00706dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "kd_tree = KDTree(data.points.positions)\n",
    "dist, idx = kd_tree.query(data.points.positions, k=4)\n",
    "mean_dist = dist[:, 1:].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5724ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_dist = torch.tensor(np.log(mean_dist), dtype=torch.float32).unsqueeze(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce2a7048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-5.5668, -5.5668, -5.5668],\n",
       "        [-5.5065, -5.5065, -5.5065],\n",
       "        [-4.5285, -4.5285, -4.5285],\n",
       "        ...,\n",
       "        [-0.6764, -0.6764, -0.6764],\n",
       "        [-2.6339, -2.6339, -2.6339],\n",
       "        [-4.1649, -4.1649, -4.1649]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_dist * torch.ones(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5e46ac19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-5.5668, -5.5668, -5.5668],\n",
       "        [-5.5065, -5.5065, -5.5065],\n",
       "        [-4.5285, -4.5285, -4.5285],\n",
       "        ...,\n",
       "        [-0.6764, -0.6764, -0.6764],\n",
       "        [-2.6339, -2.6339, -2.6339],\n",
       "        [-4.1649, -4.1649, -4.1649]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones((mean_dist.shape[0], 3), dtype=torch.float32) * torch.tensor(np.log(mean_dist)).unsqueeze(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8fda6f90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-5.5668, -5.5668, -5.5668],\n",
       "        [-5.5065, -5.5065, -5.5065],\n",
       "        [-4.5285, -4.5285, -4.5285],\n",
       "        ...,\n",
       "        [-0.6764, -0.6764, -0.6764],\n",
       "        [-2.6339, -2.6339, -2.6339],\n",
       "        [-4.1649, -4.1649, -4.1649]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones((mean_dist.shape[0], 3), dtype=torch.float32) * torch.tensor(np.log(mean_dist)).unsqueeze(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee547a21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589d2ca5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
